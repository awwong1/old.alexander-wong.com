<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Alexander Wong</title>
    <link>https://alexander-wong.com/post/</link>
    <description>Recent content in Posts on Alexander Wong</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© 2017 Alexander Wong</copyright>
    <lastBuildDate>Sun, 29 Oct 2017 19:21:37 -0600</lastBuildDate>
    
	<atom:link href="https://alexander-wong.com/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Machine Learning, Week 10</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week10/</link>
      <pubDate>Sun, 29 Oct 2017 19:21:37 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week10/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 9.
Table of Contents  Large Scale Machine Learning  Gradient Descent with Large Datasets  Learning With Large Datasets Stochastic Gradient Descent Mini-Batch Gradient Descent Stochastic Gradient Descent Convergence  Advanced Topics  Online Learning Map Reduce and Data Parallelism      Lecture notes:  Lecture17   Large Scale Machine Learning Gradient Descent with Large Datasets Learning With Large Datasets One of the best ways to get a high performance machine learning system is to supply a lot of data into a low bias (overfitting) learning algorithm.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 9</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week9/</link>
      <pubDate>Sun, 22 Oct 2017 14:21:37 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week9/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 8.
Table of Contents  Anomoly Detection  Density Estimation  Problem Motivation Gaussian Distribution Algorithm  Building an Anomaly Detection System  Developing and Evaluating an Anomaly Detection System Anomaly Detection vs. Supervised Learning Choosing What Features to Use  Multivariate Gaussian Distribution  Algorithm   Reccomender Systems  Predicting Movie Ratings  Problem Forumulation Content Based Recommendations  Collaborative Filtering  Collaborative Filtering Algorithm  Low Rank Matrix Factorization  Vectorization: Low Rank Matrix Factorization Implementational Detail: Mean Normalization      Lecture notes:  Lecture15 Lecture16   Anomoly Detection Density Estimation Problem Motivation Imagine being a manufacturor of aircraft engines.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 8</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week8/</link>
      <pubDate>Sat, 14 Oct 2017 09:21:37 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week8/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 7.
Table of Contents  Unsupervised Learning  Clustering  Introduction K-Means Algorithm Optimization Objective Random Initialization Choosing the Number of Clusters   Dimensionality Reduction  Motivation  Data Compression Visualization  Principal Component Analysis  Principal Component Analysis Problem Formulation Principal Component Analysis Algorithm  Applying PCA  Reconstruction from Compressed Representation Choosing the Number of Principal Components Advice for Applying PCA      Lecture notes:  Lecture13 Lecture14   Unsupervised Learning Clustering Introduction Unsupervised learning is the class of problem solving where when given a set of data with no labels, find structure in the dataset.</description>
    </item>
    
    <item>
      <title>Four States of Being</title>
      <link>https://alexander-wong.com/post/four-states-of-being/</link>
      <pubDate>Thu, 05 Oct 2017 21:12:55 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/four-states-of-being/</guid>
      <description>There are only four states of being, or identity. Awareness, I (self), Dream (other), Universe (all).
Awareness This is the state you are born into, the state of being when you are first conscious of external stimuli. As an entity with awareness, the only requirement is one can acknowledge receiving some form of flow, or energy.
Examples: A baby crying. An insect navigating around.
I (Self-Awareness) This is the state in which you begin to recognize one self.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 7</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week7/</link>
      <pubDate>Wed, 04 Oct 2017 15:38:02 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week7/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 6.
Table of Contents  Support Vector Machines  Large Margin Classification  Optimization Objective Large Margin Intuition  Kernels Source Vector Machines (in Practice)     Lecture notes:  Lecture12   Support Vector Machines Large Margin Classification Optimization Objective We are simplifying the logistic regression cost function by converting the sigmoid function into two straight lines, as shown here:</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 6</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week6/</link>
      <pubDate>Wed, 20 Sep 2017 15:38:02 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week6/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 5.
Table of Contents  Advice for Applying Machine Learning  Evaluating a Learning Algorithm  Evaluating a Hypothesis Model Selection and Train/Validation/Test Sets Diagnosing Bias versus Variance Regularization and Bias/Variance Learning Curves Deciding What to Do Next   Machine Learning System Design  Building a Spam Classifier  Prioritizing What to Work On Error Analysis  Machine Learning Practical Tips  How to Handle Skewed Data When to Utilize Large Data Sets      Lecture notes:  Lecture10 Lecture11   Advice for Applying Machine Learning Evaluating a Learning Algorithm Evaluating a Hypothesis Once we have done some trouble shooting for errors in our predictions by:</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 5</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week5/</link>
      <pubDate>Mon, 18 Sep 2017 15:38:02 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week5/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 4.
Table of Contents  Neural Networks: Learning  Cost Function and Backpropagation  Cost Function Backpropagation Algorithm Backpropagation Intuition  Backpropagation in Practice  Implementation Note: Unrolling Parameters Gradient Checking Random Initialization Putting it Together  Application of Neural Networks  Autonomous Driving      Lecture notes:  Lecture9   Neural Networks: Learning Cost Function and Backpropagation Cost Function Let&amp;rsquo;s define a few variables that we will need to use.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 4</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week4/</link>
      <pubDate>Tue, 12 Sep 2017 12:47:44 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week4/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 3.
Table of Contents  Neural Networks: Representation  Motivations  Non-linear Hypothesis Neurons and the Brain  Neural Networks  Model Representation I Model Representation II  Applications  Examples and Intuitions I Examples and Intuitions II Multiclass Classification      Lecture notes:  Lecture8   Neural Networks: Representation Motivations Non-linear Hypothesis Neural networks are another learning algorithm that exist in addition to linear regression and logistic regression.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 3</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week3/</link>
      <pubDate>Thu, 07 Sep 2017 00:04:44 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week3/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 2.
Table of Contents  Logistic Regression  Classification and Representation  Classification Hypothesis Representation Decision Boundary  Logistic Regression Model  Cost Function Simplified Cost Function and Gradient Descent Advanced Optimization  Multiclass Classification  Multiclass Classification: One-vs-all   Regularization  Solving the Problem of Overfitting  The Problem of Overfitting Cost Function Regularized Linear Regression Regularized Logistic Regression      Lecture notes:  Lecture6 Lecture7   Logistic Regression Classification and Representation Classification Recall that classification involves a hypothesis function which returns a discontinuous output (common example was whether or not a tumor was benign or cancerous based on size).</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 2</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week2/</link>
      <pubDate>Thu, 31 Aug 2017 14:05:35 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week2/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 1.
Table of Contents  Linear Regression with Multiple Variables  Multivariate Linear Regression  Multiple Features Gradient Descent for Multiple Variables Gradient Descent in Practice - Feature Scaling &amp;amp; Mean Normalization Gradient Descent in Practice - Learning Rate Features and Polynomial Regression  Computing Parameters Analytically  Normal Equation Normal Equation Noninvertibility   Optional Octave/MatLab Tutorial  Octave Tutorial  Basic Operations Moving Data Around Computing on Data Plotting Data Functions &amp;amp; Control Statements: for, while, if/elseif/else Vectorization      Lecture notes:  Lecture4 Lecture5   Linear Regression with Multiple Variables Multivariate Linear Regression Multiple Features Linear regression with multiple variables is known as Multivariate Linear Regression.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 1</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week1/</link>
      <pubDate>Thu, 31 Aug 2017 10:25:51 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week1/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Table of Contents  Introduction  Machine Learning  What is Machine Learning Supervised Learning Unsupervised Learning  Linear Regression with One Variable  Model Representation Cost Function &amp;amp; Intuitions Gradient Descent Gradient Descent for Linear Regression   Optional Linear Algebra  Linear Algebra Review  Matrices and Vectors Matrix Addition and Scalar Operations Matrix-Vector Multiplication Matrix-Matrix Multiplication Matrix Multiplication Properties Inverse and Transpose      Lecture notes:  Lecture1 Lecture2 Lecture3   Introduction Machine Learning What is Machine Learning  Arthur Samuel (1959): The field of study that gives computers the ability to learn without explicitly programmed.</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://alexander-wong.com/post/hello-world/</link>
      <pubDate>Sat, 12 Aug 2017 14:25:51 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/hello-world/</guid>
      <description>Although as individuals we are always in transition, I believe it is necesary to have static markers representing our current state in reference to the universe. We are mortal, we were born into this world, and inevitably we will eventually die. Consider this post to mark the beginning of a quarter life transition. I figure that the best way to measure and document this is to have an open, publicly available record of my goals and my journey in pursuing meaning in life.</description>
    </item>
    
  </channel>
</rss>