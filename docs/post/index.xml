<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Alexander Wong</title>
    <link>https://alexander-wong.com/post/</link>
    <description>Recent content in Posts on Alexander Wong</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Â© 2017 Alexander Wong</copyright>
    <lastBuildDate>Wed, 20 Sep 2017 15:38:02 -0600</lastBuildDate>
    
	<atom:link href="https://alexander-wong.com/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Machine Learning, Week 6</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week6/</link>
      <pubDate>Wed, 20 Sep 2017 15:38:02 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week6/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 5.
Table of Contents  Advice for Applying Machine Learning  Evaluating a Learning Algorithm  Evaluating a Hypothesis Model Selection and Train/Validation/Test Sets Diagnosing Bias versus Variance Regularization and Bias/Variance Learning Curves Deciding What to Do Next      Lecture notes:  Lecture10   Advice for Applying Machine Learning Evaluating a Learning Algorithm Evaluating a Hypothesis Once we have done some trouble shooting for errors in our predictions by:</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 5</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week5/</link>
      <pubDate>Mon, 18 Sep 2017 15:38:02 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week5/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 4.
Table of Contents  Neural Networks: Learning  Cost Function and Backpropagation  Cost Function Backpropagation Algorithm Backpropagation Intuition  Backpropagation in Practice  Implementation Note: Unrolling Parameters Gradient Checking Random Initialization Putting it Together  Application of Neural Networks  Autonomous Driving      Lecture notes:  Lecture9   Neural Networks: Learning Cost Function and Backpropagation Cost Function Let&amp;rsquo;s define a few variables that we will need to use.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 4</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week4/</link>
      <pubDate>Tue, 12 Sep 2017 12:47:44 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week4/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 3.
Table of Contents  Neural Networks: Representation  Motivations  Non-linear Hypothesis Neurons and the Brain  Neural Networks  Model Representation I Model Representation II  Applications  Examples and Intuitions I Examples and Intuitions II Multiclass Classification      Lecture notes:  Lecture8   Neural Networks: Representation Motivations Non-linear Hypothesis Neural networks are another learning algorithm that exist in addition to linear regression and logistic regression.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 3</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week3/</link>
      <pubDate>Thu, 07 Sep 2017 00:04:44 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week3/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 2.
Table of Contents  Logistic Regression  Classification and Representation  Classification Hypothesis Representation Decision Boundary  Logistic Regression Model  Cost Function Simplified Cost Function and Gradient Descent Advanced Optimization  Multiclass Classification  Multiclass Classification: One-vs-all   Regularization  Solving the Problem of Overfitting  The Problem of Overfitting Cost Function Regularized Linear Regression Regularized Logistic Regression      Lecture notes:  Lecture6 Lecture7   Logistic Regression Classification and Representation Classification Recall that classification involves a hypothesis function which returns a discontinuous output (common example was whether or not a tumor was benign or cancerous based on size).</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 2</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week2/</link>
      <pubDate>Thu, 31 Aug 2017 14:05:35 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week2/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Assumes you have knowledge of Week 1.
Table of Contents  Linear Regression with Multiple Variables  Multivariate Linear Regression  Multiple Features Gradient Descent for Multiple Variables Gradient Descent in Practice - Feature Scaling &amp;amp; Mean Normalization Gradient Descent in Practice - Learning Rate Features and Polynomial Regression  Computing Parameters Analytically  Normal Equation Normal Equation Noninvertibility   Optional Octave/MatLab Tutorial  Octave Tutorial  Basic Operations Moving Data Around Computing on Data Plotting Data Functions &amp;amp; Control Statements: for, while, if/elseif/else Vectorization      Lecture notes:  Lecture4 Lecture5   Linear Regression with Multiple Variables Multivariate Linear Regression Multiple Features Linear regression with multiple variables is known as Multivariate Linear Regression.</description>
    </item>
    
    <item>
      <title>Machine Learning, Week 1</title>
      <link>https://alexander-wong.com/post/coursera-machine-learning-week1/</link>
      <pubDate>Thu, 31 Aug 2017 10:25:51 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/coursera-machine-learning-week1/</guid>
      <description>Taking the Coursera Machine Learning course. Will post condensed notes every week as part of the review process. All material originates from the free Coursera course, taught by Andrew Ng.
Table of Contents  Introduction  Machine Learning  What is Machine Learning Supervised Learning Unsupervised Learning  Linear Regression with One Variable  Model Representation Cost Function &amp;amp; Intuitions Gradient Descent Gradient Descent for Linear Regression   Optional Linear Algebra  Linear Algebra Review  Matrices and Vectors Matrix Addition and Scalar Operations Matrix-Vector Multiplication Matrix-Matrix Multiplication Matrix Multiplication Properties Inverse and Transpose      Lecture notes:  Lecture1 Lecture2 Lecture3   Introduction Machine Learning What is Machine Learning  Arthur Samuel (1959): The field of study that gives computers the ability to learn without explicitly programmed.</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://alexander-wong.com/post/hello-world/</link>
      <pubDate>Sat, 12 Aug 2017 14:25:51 -0600</pubDate>
      
      <guid>https://alexander-wong.com/post/hello-world/</guid>
      <description>Although as individuals we are always in transition, I believe it is necesary to have static markers representing our current state in reference to the universe. We are mortal, we were born into this world, and inevitably we will eventually die. Consider this post to mark the beginning of a quarter life transition. I figure that the best way to measure and document this is to have an open, publicly available record of my goals and my journey in pursuing meaning in life.</description>
    </item>
    
  </channel>
</rss>